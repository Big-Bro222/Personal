---
title: "Master Thesis (Part 2)"
date: 2020-06-07
slug: "/blog/masterthesis/2"
tags:
  - AR/VR
---
### (Remote User testing Setup)


Due to the Quarantine in Paris in 2020, itâ€™s not practicle and ethical to do poilot study . So we changed our plan and we started to build a remote Usability Lab. We used the Photon Unity Network Library to fulfill the remote function.

For remote Usability Lab, we first designed three function: Be able to see what user see, be able to assist user in a third person view and be able to communicate via network.
<left>
    <img style="border-radius: 0.1125em;
    box-shadow: 0 2px 1px 0 rgba(34,36,38,.12),0 2px 5px 0 rgba(34,36,38,.08);" 
    src="https://cdn.jsdelivr.net/gh/Big-Bro222/StaticFileServer/big-bro222.github.io/posts/master-thesis-2//Remote_system.png" width = "100%" alt="Remote_system.png"/>
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">
    Figure1 System diagram
  	</div>
</left>


Based on PhotonNetwork. So the basic idea is that each photonView only belongs to one Client. We set the HoloLens application as the Master Client, and the Observation applications are syncronized accordingly.

The main function works this way: we try to syncronize their location and rotation through network, but the hightlighted interaction and complicated interaction where called by event and encoded in the virtual room scene.

We also have a third person view for the observer to better understand how the whole enviroment looks like. By switch between the first Person VR view and the Third person view, the observer can freely observe how people interact with the visaulization.
<left>
    <img style="border-radius: 0.1125em;
    box-shadow: 0 2px 1px 0 rgba(34,36,38,.12),0 2px 5px 0 rgba(34,36,38,.08);" 
    src="https://cdn.jsdelivr.net/gh/Big-Bro222/StaticFileServer/big-bro222.github.io/posts/master-thesis-2/FirstPerson.gif" width = "100%" alt="FirstPerson.gif"/>
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">
    Figure2 First Person view
  	</div>
</left>

<left>
    <img style="border-radius: 0.1125em;
    box-shadow: 0 2px 1px 0 rgba(34,36,38,.12),0 2px 5px 0 rgba(34,36,38,.08);" 
    src="https://cdn.jsdelivr.net/gh/Big-Bro222/StaticFileServer/big-bro222.github.io/posts/master-thesis-2/ThirdPerson.gif" width = "100%" alt="ThirdPerson.gif"/>
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">
    Figure3 Third Person View
  	</div>
</left>


We also implemented a 3D replay system for future use. The system is consisted of two parts, one is pulling transform data from the scene, another is an event driven system that can understand how people are interacting with the project. we calculate the time that people

<left>
    <img style="border-radius: 0.1125em;
    box-shadow: 0 2px 1px 0 rgba(34,36,38,.12),0 2px 5px 0 rgba(34,36,38,.08);" 
    src="https://cdn.jsdelivr.net/gh/Big-Bro222/StaticFileServer/big-bro222.github.io/posts/master-thesis-2//BubbleCursorMap.png" width = "100%" alt="BubbleCursorMap.png"/>
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">
    Figure4 BubbleCursorMap
  	</div>
</left>

### Thesis links
- [Thesis part 1 (Design Space initial implementation)](/blog/masterthesis/1)
- [Thesis part 2 (Remote User testing Setup) ](/blog/masterthesis/2)
- [Thesis part 3 (Resize and Interact with Mouse) ](/blog/masterthesis/3)